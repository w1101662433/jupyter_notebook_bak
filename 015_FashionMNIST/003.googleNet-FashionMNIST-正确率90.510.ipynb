{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d42871-45a0-45dd-8359-3c2e159ed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5b7916-8ab4-4aa7-8f90-9404bdeff545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "generator = torch.Generator()\n",
    "\n",
    "# 设置随机种子，确保实验可重复性\n",
    "torch.random.manual_seed(420)\n",
    "torch.cuda.manual_seed(420)\n",
    "generator.manual_seed(420)\n",
    "np.random.seed(420)\n",
    "random.seed(420)\n",
    "\n",
    "# 从\"./dataset/\"目录加载FashionMNIST数据集，如果没有则会自动下载。\n",
    "train_data = FashionMNIST(root='./dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = FashionMNIST(root='./dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_batch = DataLoader(dataset=train_data, batch_size=256,  shuffle=True, num_workers=0, drop_last=False, generator=generator)\n",
    "test_batch = DataLoader(dataset=test_data, batch_size=256,  shuffle=False, num_workers=0, drop_last=False, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9e496f-a8f6-4a3c-a85d-d4c84e6d30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义一个基本的卷积+批归一化+ReLU激活函数层\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "# 定义Inception模块\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch3x3red, kernel_size=1),\n",
    "            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, ch5x5red, kernel_size=1),\n",
    "            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, pool_proj, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "# 实现GoogleNet模型\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.conv1 = BasicConv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n",
    "        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "        \n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0393784b-b507-47bd-b727-b9055961bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 初始化一个模型，输入图片通道数为1，输出特征为10\n",
    "model = GoogleNet(num_classes=10).to(device)\n",
    "# 使用负对数似然损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# 初始化Adam优化器，设定学习率为0.005\n",
    "opt = Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bba9757-78a7-440f-8c47-88cc05f8ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.40873321890830994 accuracy: 86.45833587646484\n",
      "loss: 0.32110244035720825 accuracy: 87.5\n",
      "loss: 0.3983750343322754 accuracy: 84.375\n",
      "loss: 0.2500341534614563 accuracy: 92.70833587646484\n",
      "loss: 0.25288426876068115 accuracy: 90.625\n",
      "loss: 0.23409247398376465 accuracy: 93.75\n",
      "loss: 0.21931307017803192 accuracy: 90.625\n",
      "loss: 0.19851894676685333 accuracy: 90.625\n",
      "loss: 0.18098406493663788 accuracy: 94.79167175292969\n"
     ]
    }
   ],
   "source": [
    "# 进行9次迭代\n",
    "for _ in range(9):\n",
    "    # 遍历数据批次\n",
    "    for batch in train_batch:\n",
    "        # 将输入数据X调整形状并输入到模型\n",
    "        X = batch[0].to(device)\n",
    "        # y为真实标签\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        # 前向传播，获取模型输出\n",
    "        sigma = model.forward(X)\n",
    "        # 计算损失\n",
    "        loss = criterion(sigma, y)\n",
    "        # 计算预测的标签\n",
    "        y_hat = torch.max(sigma, dim=1)[1]\n",
    "        # 计算预测正确的数量\n",
    "        correct_count = torch.sum(y_hat == y)\n",
    "        # 计算准确率\n",
    "        accuracy = correct_count / len(y) * 100\n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "        # 更新模型参数\n",
    "        opt.step()\n",
    "        # 清除之前的梯度\n",
    "        model.zero_grad()\n",
    "    # 打印当前批次的损失和准确率\n",
    "    print('loss:', loss.item(), 'accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c65c68-392f-4a91-a5ce-0d8c7b07916b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_10764\\345735844.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sigma = model.forward(torch.tensor(test_X, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.51000213623047\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "for batch in test_batch:\n",
    "    test_X = batch[0].to(device)\n",
    "    test_y = batch[1].to(device)\n",
    "    sigma = model.forward(torch.tensor(test_X, dtype=torch.float32))\n",
    "    y_hat = torch.max(sigma, dim=1)[1]\n",
    "    correct_count += torch.sum(y_hat == test_y)\n",
    "    \n",
    "accuracy = correct_count / 10000 * 100\n",
    "print('accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a69f8-557d-43e4-a526-e5e48ad8f694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

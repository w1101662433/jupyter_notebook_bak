{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d42871-45a0-45dd-8359-3c2e159ed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5b7916-8ab4-4aa7-8f90-9404bdeff545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python39\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "generator = torch.Generator()\n",
    "\n",
    "# 设置随机种子，确保实验可重复性\n",
    "seed_value = 420\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "# 如果你使用CUDA并希望进一步确定性，可以添加下面两行代码\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "generator.manual_seed(seed_value)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation([-6,6]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化处理\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    #transforms.RandomRotation([-5,5]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化处理\n",
    "])\n",
    "\n",
    "# 从\"./dataset/\"目录加载FashionMNIST数据集，如果没有则会自动下载。\n",
    "train_data = FashionMNIST(root='./dataset/', train=True,  download=True,transform=transform)\n",
    "test_data = FashionMNIST(root='./dataset/', train=False,  download=True,transform=transform2)\n",
    "train_batch = DataLoader(dataset=train_data, batch_size=128,  shuffle=True, num_workers=0, drop_last=False, generator=generator)\n",
    "test_batch = DataLoader(dataset=test_data, batch_size=128,  shuffle=False, num_workers=0, drop_last=False, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9e496f-a8f6-4a3c-a85d-d4c84e6d30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,in_features=1,out_features=10):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_features, out_channels=64, kernel_size=3, bias=False) \n",
    "        self.adavgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.block1 = torch.nn.Sequential(self.conv1, torch.nn.BatchNorm2d(64), self.relu)\n",
    "        self.output = torch.nn.Linear(512, out_features, bias=True)\n",
    "        self.maxpool = torch.nn.AvgPool2d(2,ceil_mode=True)\n",
    "        self.downsample = torch.nn.Sequential(torch.nn.Conv2d(64, 128, kernel_size=1,stride=2,bias=False),torch.nn.BatchNorm2d(128))\n",
    "        self.downsample2 = torch.nn.Sequential(torch.nn.Conv2d(128, 256, kernel_size=1,stride=2, bias=False), torch.nn.BatchNorm2d(256))\n",
    "        self.downsample3 = torch.nn.Sequential(torch.nn.Conv2d(256, 512, kernel_size=1,stride=2, bias=False), torch.nn.BatchNorm2d(512))\n",
    "        self.conv_res = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.conv_res2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.conv_res3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "        )\n",
    "        \n",
    "        self.conv_res4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        self.conv_res5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1, stride=2, bias=False),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "        )\n",
    "        \n",
    "        self.conv_res6 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            self.relu,\n",
    "            torch.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1, bias=False),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        \n",
    "        identity = self.downsample(x)\n",
    "        x = self.conv_res(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_res2(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        identity = self.downsample2(x)\n",
    "        x = self.conv_res3(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_res4(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        identity = self.downsample3(x)\n",
    "        x = self.conv_res5(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "        x = self.conv_res6(x)\n",
    "        x = x + identity\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.adavgpool(x)\n",
    "        x = x.view(len(x), -1)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0393784b-b507-47bd-b727-b9055961bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 初始化一个模型，输入图片通道数为1，输出特征为10\n",
    "model = Model().to(device)\n",
    "# 使用负对数似然损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# 初始化Adam优化器，设定学习率为0.005\n",
    "opt = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bba9757-78a7-440f-8c47-88cc05f8ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 loss: 0.22700746357440948 accuracy: 87.5\n",
      "468 loss: 0.24418888986110687 accuracy: 88.54167175292969\n",
      "468 loss: 0.33284273743629456 accuracy: 88.54167175292969\n",
      "468 loss: 0.21082790195941925 accuracy: 93.75\n",
      "468 loss: 0.17198963463306427 accuracy: 95.83333587646484\n",
      "468 loss: 0.14737163484096527 accuracy: 92.70833587646484\n",
      "468 loss: 0.1093142032623291 accuracy: 96.875\n",
      "468 loss: 0.11496608704328537 accuracy: 94.79167175292969\n",
      "468 loss: 0.0912320539355278 accuracy: 95.83333587646484\n"
     ]
    }
   ],
   "source": [
    "# 进行9次迭代\n",
    "for _ in range(9):\n",
    "    # 遍历数据批次\n",
    "    for n_, batch in enumerate(train_batch):\n",
    "        # 将输入数据X调整形状并输入到模型\n",
    "        X = batch[0].to(device)\n",
    "        # y为真实标签\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        # 前向传播，获取模型输出\n",
    "        sigma = model.forward(X)\n",
    "        # 计算损失\n",
    "        loss = criterion(sigma, y)\n",
    "        # 计算预测的标签\n",
    "        y_hat = torch.max(sigma, dim=1)[1]\n",
    "        # 计算预测正确的数量\n",
    "        correct_count = torch.sum(y_hat == y)\n",
    "        # 计算准确率\n",
    "        accuracy = correct_count / len(y) * 100\n",
    "        # 反向传播，计算梯度\n",
    "        loss.backward()\n",
    "        # 更新模型参数\n",
    "        opt.step()\n",
    "        # 清除之前的梯度\n",
    "        model.zero_grad()\n",
    "    # 打印当前批次的损失和准确率\n",
    "    print(n_, 'loss:', loss.item(), 'accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c65c68-392f-4a91-a5ce-0d8c7b07916b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6028\\345735844.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sigma = model.forward(torch.tensor(test_X, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 93.18999481201172\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "for batch in test_batch:\n",
    "    test_X = batch[0].to(device)\n",
    "    test_y = batch[1].to(device)\n",
    "    sigma = model.forward(torch.tensor(test_X, dtype=torch.float32))\n",
    "    y_hat = torch.max(sigma, dim=1)[1]\n",
    "    correct_count += torch.sum(y_hat == test_y)\n",
    "    \n",
    "accuracy = correct_count / 10000 * 100\n",
    "print('accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb2d31-5255-48b5-b2aa-8fbdf8279277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
